{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "19366cae-81ae-4295-a138-6b87a06bd5e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "import os\n",
    "import pandas as pd\n",
    "import librosa\n",
    "import numpy as np\n",
    "import parselmouth  # For formant frequency extraction from Praat\n",
    "from parselmouth.praat import call\n",
    "import scipy.signal as signal "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e7bba42f-4810-454d-a780-21b824a79b21",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataIngestion:\n",
    "    def __init__(self, zip_file_path, extract_to_dir, output_dir):\n",
    "        self.zip_file_path = zip_file_path\n",
    "        self.extract_to_dir = extract_to_dir\n",
    "        self.output_dir = output_dir\n",
    "        self.audio_file_info_df = None\n",
    "        self.audio_features_df = None\n",
    "        self.preprocessor = AudioPreprocessing(sample_rate=16000)\n",
    "\n",
    "    @staticmethod\n",
    "    def is_audio_file(file_name):\n",
    "        \"\"\"Check if a file is an audio file based on its extension.\"\"\"\n",
    "        audio_extensions = ['.mp3', '.wav', '.ogg', '.flac', '.aac', '.m4a', '.wma']\n",
    "        return any(file_name.lower().endswith(ext) for ext in audio_extensions)\n",
    "\n",
    "    def extract_audio_files_from_zip(self):\n",
    "        \"\"\"Extract audio files from a ZIP archive and save their paths in a DataFrame.\"\"\"\n",
    "        # Create the directory if it doesn't exist\n",
    "        if not os.path.exists(self.extract_to_dir):\n",
    "            os.makedirs(self.extract_to_dir)\n",
    "\n",
    "        # Extract files from the ZIP archive\n",
    "        with zipfile.ZipFile(self.zip_file_path, 'r') as zip_ref:\n",
    "            zip_ref.extractall(self.extract_to_dir)\n",
    "\n",
    "        # Prepare a list to store audio file information\n",
    "        audio_file_info_list = []\n",
    "\n",
    "        # Walk through the extracted files\n",
    "        for root, dirs, files in os.walk(self.extract_to_dir):\n",
    "            for file in files:\n",
    "                if self.is_audio_file(file):\n",
    "                    file_path = os.path.join(root, file)\n",
    "                    folder_name = os.path.basename(root)  # Extract folder name\n",
    "                    audio_file_info_list.append({'Folder Name': folder_name, 'File Name': file, 'File Path': file_path})\n",
    "\n",
    "        # Create a DataFrame to store audio file names and paths\n",
    "        self.audio_file_info_df = pd.DataFrame(audio_file_info_list)\n",
    "        return self.audio_file_info_df\n",
    "\n",
    "    @staticmethod\n",
    "    def extract_formants(file_path):\n",
    "        \"\"\"Extract formant frequencies from an audio file using Praat-parselmouth.\"\"\"\n",
    "        snd = parselmouth.Sound(file_path)\n",
    "        formants = call(snd, \"To Formant (burg)\", 0.0, 5, 5500, 0.025, 50.0)\n",
    "        formant_freqs = [call(formants, \"Get value at time\", i, 0.5, 'Hertz', 'Linear') for i in range(1, 4)]  # F1, F2, F3\n",
    "        return formant_freqs\n",
    "\n",
    "    def extract_audio_features(self):\n",
    "        \"\"\"Extract audio features from audio files and store them in a DataFrame.\"\"\"\n",
    "        # Prepare a list to store features\n",
    "        feature_list = []\n",
    "\n",
    "        for index, row in self.audio_file_info_df.iterrows():\n",
    "            file_path = row['File Path']\n",
    "            try:\n",
    "                # Preprocess the audio file using AudioPreprocessing class\n",
    "                preprocessed_audio = self.preprocessor.preprocess(file_path)  # Apply the full preprocessing pipeline\n",
    "\n",
    "                # Preprocessed audio comes as frames after segmentation. Flatten frames for feature extraction.\n",
    "                preprocessed_audio_flat = preprocessed_audio.flatten()\n",
    "\n",
    "                # Extract MFCC features from the preprocessed audio\n",
    "                mfccs = librosa.feature.mfcc(y=preprocessed_audio_flat, sr=self.preprocessor.sample_rate, n_mfcc=40)\n",
    "                mfccs_mean = np.mean(mfccs.T, axis=0)  # Mean of MFCCs\n",
    "\n",
    "                # Extract Pitch and Pitch Contour\n",
    "                pitches, magnitudes = librosa.core.piptrack(y=preprocessed_audio_flat, sr=self.preprocessor.sample_rate)\n",
    "                pitch_mean = np.mean(pitches[pitches > 0])  # Mean pitch\n",
    "                pitch_contour = pitches[pitches > 0]  # Pitch contour\n",
    "\n",
    "                # Extract Energy\n",
    "                energy = np.sum(preprocessed_audio_flat ** 2) / np.float64(len(preprocessed_audio_flat))  # Simple energy calculation\n",
    "\n",
    "                # Extract Formant Frequencies using raw file (optional, formants usually work on raw audio)\n",
    "                formant_freqs = self.extract_formants(file_path)\n",
    "\n",
    "                # Extract Speech Rate (number of syllables per second)\n",
    "                speech_rate = len(librosa.effects.split(preprocessed_audio_flat)) / librosa.get_duration(y=preprocessed_audio_flat, sr=self.preprocessor.sample_rate)\n",
    "\n",
    "                # Extract Zero Crossing Rate\n",
    "                zcr = np.mean(librosa.feature.zero_crossing_rate(y=preprocessed_audio_flat))\n",
    "\n",
    "                # Append features to the list\n",
    "                feature_list.append({\n",
    "                    'Folder Name': row['Folder Name'],\n",
    "                    'File Name': row['File Name'],\n",
    "                    'MFCCs': mfccs_mean,\n",
    "                    'Pitch Mean': pitch_mean,\n",
    "                    'Pitch Contour': pitch_contour.tolist(),\n",
    "                    'Energy': energy,\n",
    "                    'Formant F1': formant_freqs[0],\n",
    "                    'Formant F2': formant_freqs[1],\n",
    "                    'Formant F3': formant_freqs[2],\n",
    "                    'Speech Rate': speech_rate,\n",
    "                    'Zero Crossing Rate': zcr\n",
    "                })\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing {file_path}: {e}\")\n",
    "\n",
    "        # Create a DataFrame to store audio features\n",
    "        self.audio_features_df = pd.DataFrame(feature_list)\n",
    "        return self.audio_features_df\n",
    "\n",
    "    def save_audio_data_to_csv(self):\n",
    "        \"\"\"Save audio data to separate CSV files based on folder type.\"\"\"\n",
    "        # Create the directory if it doesn't exist\n",
    "        if not os.path.exists(self.output_dir):\n",
    "            os.makedirs(self.output_dir)\n",
    "\n",
    "        # Group by folder name and save to separate CSV files\n",
    "        grouped = self.audio_features_df.groupby('Folder Name')\n",
    "        for folder_name, group_df in grouped:\n",
    "            # Define the CSV file path\n",
    "            csv_file_path = os.path.join(self.output_dir, f'{folder_name}_audio_data.csv')\n",
    "            \n",
    "            # Save the DataFrame to CSV\n",
    "            group_df.to_csv(csv_file_path, index=False)\n",
    "            print(f\"Saved {csv_file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e2608978-4cf6-4b71-8aea-2281754ad407",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AudioPreprocessing:\n",
    "    def __init__(self, sample_rate=16000, frame_size=0.025, frame_stride=0.01):\n",
    "        self.sample_rate = sample_rate\n",
    "        self.frame_size = frame_size\n",
    "        self.frame_stride = frame_stride\n",
    "\n",
    "    def load_audio(self, file_path):\n",
    "        audio, sr = librosa.load(file_path, sr=self.sample_rate)\n",
    "        return audio, sr\n",
    "\n",
    "    def noise_removal(self, audio):\n",
    "        # Basic noise reduction using a high-pass filter\n",
    "        b, a = signal.butter(1, 100 / (0.5 * self.sample_rate), btype='high')\n",
    "        audio_denoised = signal.lfilter(b, a, audio)\n",
    "        return audio_denoised\n",
    "\n",
    "    def silence_removal(self, audio, top_db=20):\n",
    "        non_silent_intervals = librosa.effects.split(audio, top_db=top_db)\n",
    "        audio_nonsilent = np.concatenate([audio[start:end] for start, end in non_silent_intervals])\n",
    "        return audio_nonsilent\n",
    "\n",
    "    def normalize(self, audio):\n",
    "        return librosa.util.normalize(audio)\n",
    "\n",
    "    def resample(self, audio, orig_sr, target_sr):\n",
    "        if orig_sr != target_sr:\n",
    "            audio_resampled = librosa.resample(audio, orig_sr=orig_sr, target_sr=target_sr)\n",
    "            return audio_resampled\n",
    "        return audio\n",
    "\n",
    "    def frame_segmentation(self, audio):\n",
    "        frame_length = int(self.frame_size * self.sample_rate)\n",
    "        frame_step = int(self.frame_stride * self.sample_rate)\n",
    "        frames = librosa.util.frame(audio, frame_length=frame_length, hop_length=frame_step)\n",
    "        return frames.T\n",
    "\n",
    "    def apply_window(self, frames):\n",
    "        window = np.hamming(frames.shape[1])\n",
    "        windowed_frames = frames * window\n",
    "        return windowed_frames\n",
    "\n",
    "    def preprocess(self, file_path):\n",
    "        # Load audio\n",
    "        audio, sr = self.load_audio(file_path)\n",
    "        \n",
    "        # Resample audio if necessary\n",
    "        audio = self.resample(audio, sr, self.sample_rate)\n",
    "        \n",
    "        # Remove noise\n",
    "        audio = self.noise_removal(audio)\n",
    "        \n",
    "        # Remove silence\n",
    "        audio = self.silence_removal(audio)\n",
    "        \n",
    "        # Normalize the audio\n",
    "        audio = self.normalize(audio)\n",
    "        \n",
    "        # Segment the audio into frames\n",
    "        frames = self.frame_segmentation(audio)\n",
    "        \n",
    "        # Apply windowing to the frames\n",
    "        windowed_frames = self.apply_window(frames)\n",
    "        \n",
    "        return windowed_frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1118e1b4-acf8-43d2-a8b4-ca9922a4e8fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "zip_file_path = r'C:\\Users\\Admin\\Desktop\\Zidio\\Speech Emotion Recognition\\archive.zip'  # Update to the correct ZIP file path\n",
    "extract_to_dir = r'extracted_audio_files'    # Update to your desired extraction directory\n",
    "output_dir = r'output_csv_files'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3c2c092e-258c-4f2b-8e83-883a1c4f6b0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Folder Name           File Name  \\\n",
      "0      OAF_angry  OAF_back_angry.wav   \n",
      "1      OAF_angry   OAF_bar_angry.wav   \n",
      "2      OAF_angry  OAF_base_angry.wav   \n",
      "3      OAF_angry  OAF_bath_angry.wav   \n",
      "4      OAF_angry  OAF_bean_angry.wav   \n",
      "...          ...                 ...   \n",
      "2795     YAF_sad   YAF_witch_sad.wav   \n",
      "2796     YAF_sad   YAF_yearn_sad.wav   \n",
      "2797     YAF_sad     YAF_yes_sad.wav   \n",
      "2798     YAF_sad   YAF_young_sad.wav   \n",
      "2799     YAF_sad   YAF_youth_sad.wav   \n",
      "\n",
      "                                              File Path  \n",
      "0     extracted_audio_files\\TESS Toronto emotional s...  \n",
      "1     extracted_audio_files\\TESS Toronto emotional s...  \n",
      "2     extracted_audio_files\\TESS Toronto emotional s...  \n",
      "3     extracted_audio_files\\TESS Toronto emotional s...  \n",
      "4     extracted_audio_files\\TESS Toronto emotional s...  \n",
      "...                                                 ...  \n",
      "2795  extracted_audio_files\\TESS Toronto emotional s...  \n",
      "2796  extracted_audio_files\\TESS Toronto emotional s...  \n",
      "2797  extracted_audio_files\\TESS Toronto emotional s...  \n",
      "2798  extracted_audio_files\\TESS Toronto emotional s...  \n",
      "2799  extracted_audio_files\\TESS Toronto emotional s...  \n",
      "\n",
      "[2800 rows x 3 columns]\n",
      "     Folder Name           File Name  \\\n",
      "0      OAF_angry  OAF_back_angry.wav   \n",
      "1      OAF_angry   OAF_bar_angry.wav   \n",
      "2      OAF_angry  OAF_base_angry.wav   \n",
      "3      OAF_angry  OAF_bath_angry.wav   \n",
      "4      OAF_angry  OAF_bean_angry.wav   \n",
      "...          ...                 ...   \n",
      "2795     YAF_sad   YAF_witch_sad.wav   \n",
      "2796     YAF_sad   YAF_yearn_sad.wav   \n",
      "2797     YAF_sad     YAF_yes_sad.wav   \n",
      "2798     YAF_sad   YAF_young_sad.wav   \n",
      "2799     YAF_sad   YAF_youth_sad.wav   \n",
      "\n",
      "                                                  MFCCs   Pitch Mean  \\\n",
      "0     [-224.4693156769982, 76.90062748574081, -25.30...  1221.440598   \n",
      "1     [-233.17992686119203, 93.78740643362411, -15.8...  1036.458966   \n",
      "2     [-227.80818092948465, 63.083954979064515, -11....  1312.541402   \n",
      "3     [-237.7189304402609, 85.89725761837914, -19.48...  1090.480014   \n",
      "4     [-269.5399905583326, 75.7107442087591, 5.68264...   923.155753   \n",
      "...                                                 ...          ...   \n",
      "2795  [-252.56711401393517, 76.16029899031767, 41.10...  1469.181443   \n",
      "2796  [-238.06340290003638, 94.0440268330944, 34.004...   767.864120   \n",
      "2797  [-225.52865516040552, 102.47349263909369, 39.4...   592.845991   \n",
      "2798  [-247.0005504061311, 89.39378301465342, 38.902...   841.684287   \n",
      "2799  [-239.5421061132439, 83.59847835645526, 35.774...   996.931501   \n",
      "\n",
      "                                          Pitch Contour    Energy  Formant F1  \\\n",
      "0     [157.44556008364344, 153.37565612252513, 157.6...  0.016220  582.702950   \n",
      "1     [156.44429892183058, 157.85028888207853, 155.3...  0.014996  547.117219   \n",
      "2     [157.2856282942717, 154.53107709418356, 154.87...  0.016288  565.563923   \n",
      "3     [154.3465517212718, 156.30265639937073, 152.45...  0.016239  551.831713   \n",
      "4     [155.59501271422073, 158.84861423013538, 154.9...  0.008114  519.149871   \n",
      "...                                                 ...       ...         ...   \n",
      "2795  [152.79431836130527, 153.4844134874157, 154.61...  0.012555  474.451007   \n",
      "2796  [158.28529676038838, 156.5052867530051, 155.91...  0.020175  478.445397   \n",
      "2797  [154.9936293965397, 154.63264308508187, 157.01...  0.022718  443.843737   \n",
      "2798  [157.0846430478968, 155.55787243131599, 158.67...  0.014627  480.108200   \n",
      "2799  [157.01522516305988, 152.57838355254285, 160.0...  0.019368  515.740293   \n",
      "\n",
      "       Formant F2   Formant F3  Speech Rate  Zero Crossing Rate  \n",
      "0     1252.761452  2422.284727     0.373832            0.109817  \n",
      "1     1348.538626  2431.915788     0.344828            0.115637  \n",
      "2     1254.799203  2412.066425     0.400000            0.119703  \n",
      "3     1293.479660  2527.755928     0.344828            0.106258  \n",
      "4      919.162439  2567.196670     0.344828            0.079311  \n",
      "...           ...          ...          ...                 ...  \n",
      "2795  1822.808228  3116.352571     0.217391            0.187320  \n",
      "2796  2683.346869  3294.511850     0.204082            0.131046  \n",
      "2797  2796.470013  4319.623639     0.243902            0.068904  \n",
      "2798  2807.971607  3283.052799     0.210526            0.112927  \n",
      "2799  2703.942914  3302.968822     0.222222            0.128435  \n",
      "\n",
      "[2800 rows x 11 columns]\n",
      "Saved output_csv_files\\OAF_Fear_audio_data.csv\n",
      "Saved output_csv_files\\OAF_Pleasant_surprise_audio_data.csv\n",
      "Saved output_csv_files\\OAF_Sad_audio_data.csv\n",
      "Saved output_csv_files\\OAF_angry_audio_data.csv\n",
      "Saved output_csv_files\\OAF_disgust_audio_data.csv\n",
      "Saved output_csv_files\\OAF_happy_audio_data.csv\n",
      "Saved output_csv_files\\OAF_neutral_audio_data.csv\n",
      "Saved output_csv_files\\YAF_angry_audio_data.csv\n",
      "Saved output_csv_files\\YAF_disgust_audio_data.csv\n",
      "Saved output_csv_files\\YAF_fear_audio_data.csv\n",
      "Saved output_csv_files\\YAF_happy_audio_data.csv\n",
      "Saved output_csv_files\\YAF_neutral_audio_data.csv\n",
      "Saved output_csv_files\\YAF_pleasant_surprised_audio_data.csv\n",
      "Saved output_csv_files\\YAF_sad_audio_data.csv\n"
     ]
    }
   ],
   "source": [
    "if not os.path.isfile(zip_file_path):\n",
    "        print(f\"Error: The ZIP file at {zip_file_path} does not exist. Please check the file path.\")\n",
    "else:\n",
    "        # Instantiate the DataIngestion class\n",
    "    data_ingestion = DataIngestion(zip_file_path, extract_to_dir, output_dir)\n",
    "\n",
    "        # Step 1: Extract audio files and get their paths\n",
    "    try:\n",
    "        df_audio_files = data_ingestion.extract_audio_files_from_zip()\n",
    "        print(df_audio_files)\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred while extracting audio files: {e}\")\n",
    "\n",
    "        # Step 2: Extract features from audio files and load them into a DataFrame\n",
    "    try:\n",
    "        df_audio_features = data_ingestion.extract_audio_features()\n",
    "        print(df_audio_features)\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred while extracting audio features: {e}\")\n",
    "\n",
    "        # Step 3: Save the audio data to separate CSV files based on folder type\n",
    "    try:\n",
    "        data_ingestion.save_audio_data_to_csv()\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred while saving audio data to CSV files: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff14ac23-9d0a-4a3e-9b45-1c8699652f8f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
